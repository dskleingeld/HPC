%
% verslag.tex   18.2.2019
% Voorbeeld LaTeX-file voor verslagen bij Kunstmatige Intelligentie
% http://www.liacs.leidenuniv.nl/~kosterswa/AI/verslag.tex
%
% Gebruik:
%   pdflatex verslag.tex
%

\documentclass[10pt]{article}

\parindent=0pt

\usepackage{fullpage}

\frenchspacing
\usepackage{array} 
\usepackage{microtype}
\usepackage{scrextend}
\usepackage[english,english]{babel}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{hyperref}
%\usepackage{amsmath}
%\usepackage{listings}
\usepackage{subcaption}

% Er zijn talloze parameters ...
%\lstset{language=C++, showstringspaces=false, basicstyle=\small,
%  numbers=left, numberstyle=\tiny, numberfirstline=false, breaklines=true,
%  stepnumber=1, tabsize=8,
%  commentstyle=\ttfamily, identifierstyle=\ttfamily,
%  stringstyle=\itshape}

%\usepackage[setpagesize=false,colorlinks=true,linkcolor=red,urlcolor=blue,pdftitle={Het grote probleem},pdfauthor={David Kleingeld}]{hyperref}

\author{David Kleingeld, s1432982}
\title{Lu factoring Sparse matrices}

\begin{document}

\selectlanguage{english}

\maketitle

\section{Introduction}
Many problems in science depend on solving linear systems. To speed this up LU factorization is used. It can be viewed as a matrix form of Gaussian elimination. LU factorization was introduced by polish mathematician Tadeusz Banachiewicz \cite{lu}.
Often these matrices are extremely large while containing few non zero entries, so called sparse matrices. The LU factorization can be sped up by skipping these entries. There are a number of schemes to store only non zero entries for sparse matrices. The simplest, Dictionary of keys, stores the value, row and column for each non zero entry. Here we have implemented a Sparse LU Factorization kernel using compressed row storage. With compressed row storage the non zero entries in each rows are stored after each other and while we keep track of their column \cite{compressedRowStorage}. We begin with the implementation, how we validated it, how we benchmark, the results and finally we end with a discussion of the validation and benchmark where we also point out possible improvements. 

\section{Implementation}

During Lu factoring we traverse the columns of the matrix, for each column we designate the element on the diagonal in that column the pivot. We add the row with this pivot to the rows below it scaled such that the elements below the pivot become zero. This is problematic when the pivot value is small. Then the rows below might be scaled by a very large factor. Future pivot will now have extremer values reducing numerical precision. 
We can mitigate most of this using partial pivoting. For each pivot we check if there is a row with a larger value in the column below it. If there is we exchange rows so the larger value is now the current pivot. This way avoid scaling by large factors most of the time. We keep a list of applied row interchanges, using it we can still solve the original system.

Another difficulty is actually adding two rows. As this is the key to the algorithm this happens often. When we add two sparse rows more non zero elements can appear in the resulting row. However at the same time we change elements below pivots to zero, thus non zero values will also disappear. We store the compressed rows after one another, thus expanding is not an option. Instead, when a row needs to expand we move it after the last row. This creates gaps in between compressed rows reducing data locality which reduces performance and increasing the memory needed. We solve this by moving all rows to a new memory space every once in a while. Then they are next to each other again.

\section{Validation}
\label{sec:val}
We validate our factorization by applying it to solve a known linear systems. To create these systems we use a number of matrices from Matrix Market. We do this by taking the dot product of known solution vectors and various matrices creating different systems of equations. Using the created LU factorization of the matrices we then compute solutions to the systems. If the computed solutions matches the known solution vectors our LU factorization algorithm must be correct. 

For each solved system we store a relative errors: $\frac{||\widetilde{x}-x||}{||x||}$. Here $\widetilde{x}$ is the solution computed using our implementation and $x$ the actual solution known from the solution vector. $||x||$ denotes the Euclidean Norm: $\sqrt{\Sigma x_i^2}$.

We used the following matrices from Matrix-Market:
\begin{multicols}{2}
\begin{enumerate}
    \item HB/mcfe
    \item Schenk\_IBMNA/c-21
    \item Oberwolfach/flowmeter5
    \item Averous/epb1
    \item Grund/meg4
    \item Lucifora/cell1
    \item Gaertner/nopoly
    \item Bai/mhd4800b
    \item FIDAP/ex10
    \item Okunbor/aft01
\end{enumerate}
\end{multicols}

We gave the solution vectors five distinct patterns:

\begin{description}
    \item [ones] all ones
    \item [point ones] all value $0.1$
    \item [alternating ones] all alternating $+1$ and $-1$
    \item [alternating fives] all alternating $+5$ and $-5$
    \item [alternating hundreds] all alternating $+100$ and $-100$
\end{description}

\section{Benchmark}
For each of the matrices we benchmark the time it takes to factorize and the time it takes to solve each created linear systems. The benchmarks were carried out on the Linux systems on the Core i7 machines in room 302/304 at the LIACS.

\section{Results}
In \autoref{tab:errors} we see the relative error per solution vector per matrix as defined in \autoref{sec:val}. Then in \autoref{tab:factoring} we show the time it takes to factor the different matrices. The reported run time is in seconds. Finally in \autoref{tab:solving} we have the run time needed to solve all the different systems for each of the matrices, again in seconds.

\begin{table}
    \begin{tabular}{ l c c c c c }
    \firsthline
    \multicolumn{6}{c}{Relative Error (seconds)} \\
    \cline{2-6}
    Matrix & ones & point ones & alternating ones & alternating fives & alternating hundreds \\
    \hline
    HB/mcfe & 0.000000 & 0.000000 & 0.000000 & 0.000000 & 0.000000 \\
    Schenk\_IBMNA/c-21 & 0.000000 & 0.000000 & 0.000000 & 0.000000 & 0.000000 \\
    Oberwolfach/flowmeter5 & 0.000000 & 0.000000 & 0.000000 & 0.000000 & 0.000000 \\
    Averous/epb1 & 0.000000 & 0.000000 & 0.000000 & 0.000000 & 0.000000 \\
    Grund/meg4 & 0.000000 & 0.000000 & 0.000000 & 0.000000 & 0.000000 \\
    Lucifora/cell1 & 0.002045 & 0.001476 & 0.001259 & 0.001211 & 0.001189 \\
    Gaertner/nopoly & infinite & 1.908226 & 0.021489 & 0.012033 & 0.007542 \\
    Bai/mhd4800b & 0.000000 & 0.000000 & 0.000000 & 0.000000 & 0.000000 \\
    FIDAP/ex10 & 0.000000 & 0.000000 & 0.000000 & 0.000000 & 0.000000 \\
    Okunbor/aft01 & 0.000000 & 0.000000 & 0.000000 & 0.000000 & 0.000000 \\
    \lasthline
    \end{tabular}
    \caption{Relative error for all the solution vectors for all matrices.}
    \label{tab:errors}
\end{table}

\begin{table}
    \begin{tabular}{ l c c c }
    \firsthline
    Matrix & Factoring time (seconds) & Matrix Size & Number of non zeros \\
    \hline
    HB/mcfe & 0.079421 & 765x765 & 24382\\
    Schenk\_IBMNA/c-21 & 21.411541 & 3509x3509 & 17833\\
    Oberwolfach/flowmeter5 & 5.505239 & 9669x9669 & 67391\\
    Averous/epb1 & 18.281949 & 14734x14734 & 95053\\
    Grund/meg4 & 2.678350 & 5860x5860 & 26324\\
    Lucifora/cell1 & 1.785907 & 7055x7055 & 34855\\
    Gaertner/nopoly & 136.847555 & 10774x10774 & 40808\\
    Bai/mhd4800b & 0.161034 & 4800x4800 & 16160\\
    FIDAP/ex10 & 0.429020 & 2410x2410 & 28625\\
    Okunbor/aft01 & 7.076001 & 8205x8205 & 66886\\
    \lasthline
    \end{tabular}
    \caption{Time it takes to LU-Factor different matrices in seconds. Compared to their size and number of non zeros.}
    \label{tab:factoring}
\end{table}

\begin{table}
    \begin{tabular}{ l c c c c c }
    \firsthline
    \multicolumn{6}{c}{Solving Run time} \\
    \cline{2-6}
    Matrix & ones & point ones & alternating ones & alternating fives & alternating hundreds \\
    \hline
    HB/mcfe & 0.000239 & 0.000180 & 0.000178 & 0.000178 & 0.000179 \\
    Schenk\_IBMNA/c-21 & 0.011501 & 0.011447 & 0.011552 & 0.011226 & 0.011222 \\
    Oberwolfach/flowmeter5 & 0.003515s & 0.003044 & 0.002929 & 0.002888 & 0.002866 \\
    Averous/epb1 & 0.008963 & 0.009685 & 0.008836 & 0.009996 & 0.008885 \\
    Grund/meg4 & 0.002010 & 0.001674 & 0.001583 & 0.001562 & 0.001550 \\
    Lucifora/cell1 & 0.000158 & 0.000147 & 0.000038 & 0.000040 & 0.000026 \\
    Gaertner/nopoly & 0.034487 & 0.033298 & 0.033214 & 0.033124 & 0.032524 \\
    Bai/mhd4800b & 0.000149 & 0.000066 & 0.000066 & 0.000065 & 0.000065 \\
    FIDAP/ex10 & 0.000564 & 0.000398 & 0.000386 & 0.000385 & 0.000383 \\
    Okunbor/aft01 & 0.005008 & 0.004737 & 0.005241 & 0.004814 & 0.004735 \\
    \lasthline
    \end{tabular}
    \caption{Runtime solving the different solution vectors for all matrices in seconds.}
    \label{tab:solving}
\end{table}

\section{Discussion}
We see our implementation fails to correctly factor or solve Lucifora/cell1 or Gaertner/nopoly. The last one even reports a extremely high error on the system of equations created with the all ones solution vector. The nopoly matrix also has the highest run time at $137$ seconds. This initially surprised us as the Averous/epb1 matrix has an even larger size and more non zeros entries. We expect the non zeros are spread over different columns in Gaertner/nopoly causing a lot of non zeros to appear during the factorization. Gaertner/nopoly also has the largest run time for solving the different systems. This is consistent with it getting the most non zero values during factoring. The smallest matrix has the lowest factoring time while matrices with a lower number of non zeros at the start have a dramatically higher run time. This is again caused by many more non zeros appearing in the larger matrices then in the smallest.

Finally we see a number of possible optimization to the current implementation:
\begin{enumerate}
\item As the density of the matrices increases during factoring the relative overhead of working in compressed row format grows. Switching to a normal dense matrix after some critical point will provide a speedup in factoring and solving. 

\item Currently rows need to be moved as soon as an element needs to be added. We can reserve some space between rows to allow a row to grow without having to be moved. 

\item When adding two rows together they are added into a third dense row. However when changing this resulting row back to a sparse format we need to iterate over the complete dense row to find all the non zero values. Keeping a list of the indices of the non zeros in the dense row would allow us to skip this and speed up the factoring.

\item Currently values and column indexes are stored in separate large continues arrays. However both are often used simultaneously. We might get a speedup if we store value and corresponding column as a pair in a single continues array. 
\end{enumerate}

\clearpage
\bibliography{main.bib}
\bibliographystyle{IEEEtran}

\end{document}